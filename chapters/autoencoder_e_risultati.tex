%!TEX TS-program = pdflatex
%!TEX root = tesi.tex
%!TEX encoding = UTF-8 Unicode

\chapter{Modello e Risultati}

Breve intuizione sugli AE
\todo[inline]{TODO recap capitolo}
\todo[inline]{TODO recap capitolo}
\todo[inline]{TODO recap capitolo}
\todo[inline]{TODO recap capitolo}
\todo[inline]{ipotizzo almeno 5 righe}

\todo[inline]{sommario capitolo}
% descrizione architettura migliore e a chi ci siamo ispirati N.R.
\todo[inline]
{
  Preambolo sulla accuratezza dei modelli creati
  Problema dell'AE perché non fornisce accuratezza, come parametro di valutazione si è utilizzata la loss
  La loss non poteva essere usata come discrtiminatoe perché troppo poco sensibile all'errore di presenza-nonpreseena della colla
  Un altro criterio di valutazione era una verifica a mano della qualità della differenza conforme in out

  Descrivere architettura migliore
  Descrivere post-processing a valle
}

\section{La struttura di un Autoencoder}
Un \textit{Autoencoder}(AE) è un particolare tipo di rete neurale.
Può essere diviso in due componenti: il primo viene chiamato \textit{encoder}, mentre il secondo prende il nome di \textit{decoder}.
Lo scopo dell'\textit{encoder} è codificare il dato in ingresso in una versione compressa.
Sia $n$ la dimensionalità dell'\textit{input}.
Quando il dato raggiunge il collo di bottiglia dell'AE, ovvero la parte centrale della rete, ha raggiunto il livello di massima compressione, sia $m$ la sua nuova dimensionalità con $m<n$.
Lo spazio $m$-dimensionale in cui l'informazione è stata mappata viene chiamato spazio latente o spazio nascosto.
Ora il dato può essere decompresso dal \textit{decoder}, in questo modo verrà riportato alle sue dimensioni originali, cioè mappato nello spazio $n$-dimensionale di partenza.

Visto dall'esterno, il compito di un \textit{autoencoder} è quello di ritornare un valore il più simile al dato in ingresso.
Durante l'allenamento, fissato $m$ con un valore che dipende dalla forma della rete, si vuole trovare il miglior spazio latente possibile.
Dove con migliore si intende quello spazio di cardinalità $m$ che permette di mantenere tutte le informazioni caratterizzanti dell'input.
Riformulando quanto detto: un'\textit{autoencoder} può essere visto come una funzione $f$ rassomigliante la funzione identità, ma al cui intero c'è un vincolo tale da rendere il compito di restituzione dell'\textit{input} non banale.

Come viene spiegato da Andrew Ng in \cite{ng_sparse_ae}, gli \textit{autoencoder} fanno parte degli algoritmi di apprendimento non supervisionato.
Cioè di quella classe di algoritmi, in contrapposizione a quelli ad apprendimento supervisionato, che non ha bisogno di dati etichettati; anzi vengono usati proprio per trovare nuovi pattern e correlazioni tra gli elementi del \textit{dataset}.
Come gli algoritmi \textit{K-Means} e \textit{DBSCAN}, entrambi di \textit{clustering}, permettono di raggruppare nuvole di punti con caratteristiche simili. % TODO citare?
%I gruppi così creati possono far risaltare degli andamenti dei dati 
Un AE è non supervisionato perché, a priori, non conosciamo la forma che verrà data allo spazio latente. % TODO espandere?

Gli \textit{autoencoder} più semplici sono composti da due strati densamente connessi di neuroni: il primo funge da \textit{encoder} ed ha un numero di unità pari alla dimensione dello spazio latente; il secondo ha tante unità quanto la dimensione dell'\textit{input}, quindi funge da \textit{decoder}.
L'architettura appena descritta può essere osservata in figura~\ref{fig:semplice_ae}, notare la tipica forma a clessidra.

\begin{figure}[ht] % TODO rifare con tikz
  \begin{center}
    %\centering\includegraphics[width=.4\textwidth]{example-image}
    \centering\includegraphics[width=\textwidth]{simple_ae}
  \end{center}
  \caption{Architettura di un semplice \textit{autoencoder}}
  \label{fig:semplice_ae}
\end{figure}

Gli \textit{autoencoder} come quello in figura~\ref{fig:semplice_ae} hanno dato risultati equiparabili, se non migliori, a quelli ottenuti con metodi di \textit{dimensionality reduction} classici (\textit{cfr}. \cite{ng_sparse_ae},\cite{pca_vs_ae_1}).
\todo[noline]{\\rivedere\\tutto\\questo\\pezzetto\\}
Essendo gli AE delle reti neurali, è possibile aggiungere vari strati densi, come si vede in figura~\ref{fig:stacked_ae}.
Questi \textit{autoencoder} prendono il nome di AE multi-strato o \textit{stacked autoencoder} ed hanno capacità astrattive maggiori. % TODO stai attento
Allo stesso modo è anche possibile aggiungere strati convolutivi, convolutivi trasposti oppure di \textit{down} ed \textit{up-sampling}.

\begin{figure}[ht] % TODO rifare con tikz
  \begin{center}
  % https://www.researchgate.net/figure/Stacked-autoencoders-architecture_fig21_319524552
    \centering\includegraphics[width=0.7\textwidth]{stacked_ae}
  \end{center}
  \caption{Architettura di un \textit{stacked autoencoder}}
  \label{fig:stacked_ae}
\end{figure}

\paragraph{Strati Convolutivi}
Un \textit{convolutional layer} è uno strato in cui i pesi hanno la forma di un filtro convolutivo, in questo modo verrà mantenuta anche dell'informazione spaziale.
In pratica la rete si adatta in modo che i filtri lascino passare, o mettano in evidenza, soltanto quelle caratteristiche utili allo svolgimento del compito.
Come viene mostrato molto bene in \cite{conv_arithm}, questo tipo di convoluzioni è una generalizzazione parametrica delle convoluzioni descritte a pagina \pageref{conv_para}.

Innanzitutto è bene elencare i parametri che caratterizzano uno strato di questo tipo, per semplicità si suppone che le immagini ed i \textit{kernel} utilizzati siano sempre quadrati:
\begin{itemize}
  \item $n$ indica il lato dell'immagine in ingresso;

  %\item $m$ indica il lato dell'immagine in uscita;

  \item $k$ indica il lato del filtro.
    Si ricorda che i valori all'interno del filtro sono i pesi che dovranno essere imparati;

  \item $p$ indica quanto \textit{zero padding} aggiungere all'immagine in ingresso.
    Con \textit{zero padding} si intende l'aumentare la dimensione dell'input aggiungendo righe e colonne di zeri.
    Il risultato dell'applicazione del \textit{padding} con $p=1$ può essere osservato in figura~\ref{fig:conv_layer_1ch_p1_s2};

  \item $s$ indica il passo, in inglese \textit{stride}, con cui il filtro viene mosso sull'immagine in ingresso.
    In figura~\ref{fig:conv_layer} sono riportati i risultati che si ottengono con passi differenti;

  \item con $ch_{in}$ si specifica quanti sono i canali in ingresso, ad esempio se l'immagine in \textit{input} è in scala di grigi si avrà $ch_{in} = 1$;

  \item con $ch_{out}$ si specifica quanti sono i canali in uscita.

\end{itemize}
% TODO
%Fissata un valore $k$ per la dimensione del \textit{kernel}, in figura~\ref{fig:conv_layer_1ch} $k=3$, 
L'equazione \ref{eq:conv} mostra la relazione che intercorre tra i vari parametri dello strato convolutivo e la dimensione $m$ dell'immagine in uscita.
\begin{equation} \label{eq:conv}
  m = \frac
  {n + 2p - f}
  {s} 
  + 1
\end{equation}
Si fa notare che le convoluzioni descritte a pagina \pageref{conv_para} equivalgono ad impostare, con $k$ dispari, i parametri $p=\lfloor k/2 \rfloor$, $s=1$, $ch_{in}=1$ (oppure 3 a seconda del caso) e $ch_{out}=1$.
Infatti l'immagine in uscita che si ottiene ad esempio con l'operatore Sobel ha dimensioni pari a quelle dell'immagine in ingresso.

Osservando le architetture delle reti convolutive VGG~\cite{vgg} e ResNet~\cite{resnet} ci si accorge che, fatta eccezione per i primi \textit{layer}, gli strati hanno un numero di canali in ingresso ed in uscita dell'ordine delle centinaia.
Nel caso del primo \textit{layer} dell'architettura VGG11 si ha $ch_{in} = 3$ e $ch_{out} = 64$, mentre per il secondo si ha $ch_{in} = 64$ e $ch_{out} = 128$.
Una delle motivazioni è che avere più canali significa avere più \textit{kernel}, quindi anche più possibilità di apprendimento.
Infatti, prendendo in considerazione un solo strato convolutivo, il numero di kernel è dato da $n_k = ch_{in}*ch_{out}$, mentre il numero di parametri modificabili durante l'allenamento è $n_k * k * k$.
%Infatti, prendendo in considerazione uno strato convolutivo che prende in ingresso un'immagine in scala di grigi
%Con semplici calcoli si può vedere come il numero di parametri 
% TODO nota sul numero di parametri da imparare 
% TODO cosa manca da dire??

% TODO magari si può mettere in modo più carino
\begin{figure}[ht]
  \begin{center}
  \begin{tabular}{cc}
    \begin{subfigure}{.49\linewidth}
      \centering\includegraphics[width=\textwidth]{conv_example}
      \caption{$ch_{out}=1$, $p=0$ e $s=1$}
      \label{fig:conv_layer_1ch}
    \end{subfigure} &

    \begin{subfigure}{.49\linewidth}
      \centering\includegraphics[width=\textwidth]{conv_example_1}
      \caption{$ch_{out}=1$, $p=1$ e $s=2$}
      \label{fig:conv_layer_1ch_p1_s2}
    \end{subfigure}

    %\begin{subfigure}{.45\linewidth} % TODO
    %  \centering\includegraphics[width=\textwidth]{example-image} % mettere immagine con volumi simile a quella di Ng nel video
    %  \caption{A tre canali}
    %  \label{fig:conv_layer_3ch}
    %\end{subfigure}

  \end{tabular}
  \caption{Esempio di strati convolutivi}
  \label{fig:conv_layer}
  \end{center}
\end{figure}

\paragraph{Strati di Down-Sampling}
È stato dimostrato empiricamente che inserire degli strati il cui compito è ridurre le dimensioni dell'\textit{input}, aiuta le reti convolutive ad ottenere risultati migliori.
Infatti sia l'architettura VGG che quella ResNet sfruttano ampiamente un tipo di \textit{layer} chiamato Max-Pooling.
Quest'ultimo, osservabile in figura~\ref{fig:pool_layer}, assomiglia ad un \textit{convolutional layer} ma non ha parametri apprendibili.
Infatti il filtro ritorna semplicemente il massimo dell'area su cui è stato posizionato.
La dimensione del \textit{kernel} e lo \textit{stride} scelto definiscono la dimensione dell'output.
Solitamente uno strato di questo tipo viene utilizzato per dimezzare $n$, cioè è ottenibile impostando $k=2$ e $s=2$.

\begin{figure}
\centering
\begin{minipage}{.65\textwidth}
  \centering
  \includegraphics[width=\linewidth]{max-pool}
    \caption{Esempio di strato max-pooling}
    \label{fig:pool_layer}
\end{minipage}%
\begin{minipage}{.35\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{conv-transposed}
    \caption{Esempio di strato convolutivo trasposto}
    \label{fig:conv-transposed}
\end{minipage}
\end{figure}

Fin'ora sono stati descritti gli strati comuni a tutte le reti convolutive, ora verranno illustrati due \textit{layer} elusivi degli \textit{autoencoder}.

\paragraph{Strati di Up-Sampling}
Come il nome suggerisce, lo Up-Sampling \textit{layer} effettua un'operazione opposta a quella di uno strato di Down-Sampling.
Nello specifico aumenta le dimensioni dell'\textit{input} riempendo gli spazi creati con medie tra gli elementi esistenti oppure ripetendoli.

\paragraph{Strati Convolutivi Trasposti}
Lo scopo di questi strati è simulare l'opposto di un'operazione convolutiva: se una convoluzione riduce la dimensione del dato in ingesso, una convoluzione trasposta deve aumentarlo.
Il modo più semplice per ottenere questo effetto è effettuare una convoluzione con un \textit{zero padding} sufficientemente grande, come si vede in figura~\ref{fig:conv-transposed}.
% TODO spiegare perché trasposto
%Viene usato il termine trasposto perché una convoluzione può 
\todo[inline]{spiegare come i convolutivi possono essere rappresentati da matrici}

\section{Obbiettivi}
In figura~\ref{fig:obbiettivo_in_out_diff} sono riportate tre immagini per chiarire in che modo gli \textit{autoencoder} sono stati sfruttati per classificare Conformi e Scarti.
La figura~\ref{fig:obbiettivo_in} illustra uno Scarto.
L'immagine riportata in figura~\ref{fig:obbiettivo_out} è quella che si vorrebbe ottenere dall'AE a partire dallo Scarto appena illustrato.
Notare come si vorrebbe che il pezzo fosse riprodotto il più fedelmente possibile, ma che l'informazione della colla venisse rimossa.
In questo modo sarebbe possibile effettuare una differenza \textit{pixel} per \textit{pixel} tra immagine in ingresso ed immagine in uscita (detta anche ricostruita) ottenendo così un risultato simile a quello in figura~\ref{fig:obbiettivo_diff}.

Nel caso migliore possibile la classificazione verrebbe effettuata verificando se nell'immagine differenza tutti i valori sono zero.
Ossia l'immagine in ingresso appartiene alla classe Conforme ed è stata ricostruito alla perfezione.
Dato che ci si aspetta che l'\textit{autoencoder} non ricostruisca la colla nell'immagine in uscita, nell'immagine differenza ci sarà un'area di \textit{pixel} con valori in assoluto maggiori di zero.

È impossibile che l'\textit{autoencoder} raggiunga una precisione così alta, infatti è molto più infatti che l'immagine ricostruita sia soltanto un'approssimazione dell'immagine in ingresso.
Si ricorda che molto probabilmente l'AE rimuoverà tutte quelle caratteristiche particolari di un pezzo (graffi, macchie, \dots ), perché sono rumore rispetto ad una carcassa media.

Quindi si può affermare che la classificazione è divisa in due parti: nella prima l'immagine viene elaborata dall'\textit{autoencoder}; nella seconda l'immagine in ingresso e quella in uscita vengono confrontate, questa parte prende il nome di \textit{post-processing}.
L'effettiva classificazione viene eseguita in quest'ultima parte.

\begin{figure}[ht] % TODO
  \begin{center}
    \begin{tabular}{ccc}

      \begin{subfigure}{.3\linewidth}
        \centering\includegraphics[width=\textwidth]{example-image}
        \caption{Immagine in ingresso}
        \label{fig:obbiettivo_in}
      \end{subfigure} &

      \begin{subfigure}{.3\linewidth}
        \centering\includegraphics[width=\textwidth]{example-image}
        \caption{Immagine ricostruita}
        \label{fig:obbiettivo_out}
      \end{subfigure} &

      \begin{subfigure}{.3\linewidth}
        \centering\includegraphics[width=\textwidth]{example-image}
        \caption{Immagine differenza}
        \label{fig:obbiettivo_diff}
      \end{subfigure}

    \end{tabular}
    \caption{TODO in out diff}
    \label{fig:obbiettivo_in_out_diff}
  \end{center}
\end{figure}

\section{Metriche di Valutazione}
Definire delle metriche per stabilire quali architetture preformassero meglio è stata una parte critica.
Infatti gli \textit{autoencoder} potevano essere confrontati solo tramite due criteri: uno numerico, ossia la \textit{MSE Loss} ottenuta durante l'allenamento, ed uno qualitativo, cioè osservare la qualità generale delle immagini generate.
Purtroppo nessuna delle due metriche permette di ottenere delle percentuali esatte sull'accuratezza delle classificazioni.
Tali dati numerici sono stati ottenuti soltanto quando le immagini differenza sono risultate soddisfacenti e si è quindi potuto sviluppare l'algoritmo di \textit{post-processing}.
\todo{c'è da dire altro?}


\section{Il Modello}
L'architettura illustrata in figura~\ref{fig:ae16_arch}\footnote{L'immagine è stata generata usando \url{https://github.com/HarisIqbal88/PlotNeuralNet}} ha dato i risultati migliori. % TODO dire meglio
Elenchiamo le sue caratteristiche principali:
\begin{itemize}
  \item l'immagine in ingresso è in scala di grigi e di lato $200$ \textit{pixel};

  \item ogni strato convolutivo o convolutivo trasposto ha filtri di dimensione $5$x$5$, ha \textit{stride} pari a $1$, non ha nessun \textit{padding} e tutti (tranne il primo e l'ultimo strato) hanno $ch_{in}=ch_{out}=32$.
    %Il primo strato ha un canale ingresso, dato che l'\textit{input} non è a colori,
    Inoltre tutti i \textit{layer} utilizzano la funzione di attivazione \textit{ReLU}, fatta eccezione per l'ultimo in cui è presente la funzione sigmoidea.
    Infatti le immagini, prima di essere passate alla rete, vengono normalizzate in $[0,1]$, cioè facilita i calcoli effettuati all'interno dell'\textit{autoencoder}.
    L'output della rete, appartenente a $[0,1]$, verrà mappato nuovamente nell'intervallo $[0,255]$.

  \item tutti i \textit{max-pool layer} hanno sia il filtro che il passo pari a 2;

  \item il primo strato denso prende un vettore di $24*24*32=18432$ valori e lo mappa in uno spazio $2000$-dimensionale.
    Questa corrisponde alla massima compressione dell'informazione;

  \item il secondo strato denso effettua l'operazione opposta, mappando il vettore dello spazio latente in uno che possa avere le dimensioni di $24*24*32$.

\end{itemize}
%TODO fare tabella con i parametri di ogni strato?
Complessivamente la rete deve imparare  $73 832 000$ parametri.
Di questi metà si trovano nell'\textit{encoder} e metà nel \textit{decoder}.
Questo valore potrebbe sembrare grande ma, osservando che la VGG11~\cite{vgg} ha più di 130 milioni di parametri, risulta ragionevole.
Si fa notare che la maggior parte dei parametri è contenuto nei due strati densi.
Sappiamo che il numero di parametri di uno strato è dato da $n * m$ con $n$ ed $m$le dimensioni dei vettori in ingresso ed in uscita.
Nel nostro caso abbiamo due strati da $18432 * 2000 = 36 864 000$ parametri l'uno.
I quattro \textit{layer} convolutivi e convolutivi trasposti da 32 canali in ingresso ed in uscita hanno $25600$ parametri ciascuno.
\todo[noline]{cos'altro da dire?}

\begin{figure}[ht]
  \begin{center}
    \includegraphics[width=.9\textwidth]{ae16}
    \caption{TODO architettura della rete}
    \label{fig:ae16_arch}
  \end{center}
\end{figure}
\todo{rifai disegno architettura i conv trans sono svaccati}

L'allenamento del modello in figura~\ref{fig:ae16_arch} è stato effettuato sui Conformi del \textit{dataset}, processati come descritto a pagina~\pageref{prep} e seguenti.
In questa fase non sono stati utilizzati né gli Scarti né gli Scarti Sintetici.

Durante l'allenamento si è utilizzata la \textit{MSE Loss} confrontando lo Scarto tra l'immagine in ingresso e l'immagine ricostruita.
Nel grafico in figura~\ref{fig:loss_plot} si può notare come la \textit{loss} scenda in modo repentino nelle prime 5 epoche per poi stabilizzarsi.
Il tasso di apprendimento\footnote{In inglese \textit{learning rate}} è stato gestito dinamicamente: se al passare delle epoche la \textit{loss} non è calata, allora il tasso di apprendimento viene diviso per un fattore dieci.

\begin{figure}[ht] % TODO sarebbe da cambiare
  \begin{center}
    \includegraphics[width=0.5\textwidth]{loss_plot}
    \caption{Andamento della \textit{loss} e del \textit{learning rate} al passare delle epoche}
    \label{fig:loss_plot}
  \end{center}
\end{figure}

Ogni cinque epoche è stata generata un'immagine con alcuni Conformi in ingresso  ed in uscita.
È interessante notare, osservando figura~\ref{fig:epoch_0}, come le prime ricostruzioni siano tutte uguali.
Nella figura sono riportati, in alto, i sei esemplari dati in \textit{input} alla rete, mentre in basso sono mostrate le loro ricostruzioni.
Probabilmente questo è dovuto al fatto che i pesi si distribuiscono fin da subito in modo da catturare le proprietà comuni a tutte le immagini, ad esempio l'area nera della maschera e gli anelli concentrici.
In figura~\ref{fig:epoch_45} è riportato un altro gruppo di Conformi assieme alle ricostruzioni relative all'epoca numero quarantacinque.
Ci si accorge subito che le immagini in uscita risultano meno sgranate e che in alcune di esse sono state generate perfino macchie ed aree più scure.
Come ci si poteva aspettare la superficie delle immagini in \textit{output} risulta molto più lisca e priva della maggior parte dei graffi.

\begin{figure}[ht] % TODO sarebbe da cambiare
  \begin{center}
    \includegraphics[width=.65\textwidth]{in_out_epoch_0}
    \caption{In alto 6 immagini Conformi in \textit{input}, in basso la loro ricostruzione alla prima epoca}
    \label{fig:epoch_0}
  \end{center}
\end{figure}

\begin{figure}[ht] % TODO sarebbe da cambiare
  \begin{center}
    \includegraphics[width=.65\textwidth]{in_out_epoch_45}
    \caption{In alto 6 immagini Conformi in \textit{input}, in basso la loro ricostruzione alla 45-esima epoca}
    \label{fig:epoch_45}
  \end{center}
\end{figure}

\clearpage
\section{Post-Processing}
Dopo aver osservato la precisione con cui i Conformi vengono riprodotti bisogna verificare come l'AE si comporti con le immagini della classe Scarto.
In figura~\ref{fig:scarti_in_out} si possono osservare alcuni esempi di Scarti all'ingresso e all'uscita dell'\textit{autoencoder}.
Notare come nelle prima coppia la colla sia stata rimossa molto bene e la carcassa ricostruita abbia alcune caratteristiche di quella originale.
Purtroppo nell'ultima coppia si vede come le zone più scure tipiche di alcune carcasse con colla, causino la creazione di rumore nell'immagine in \textit{output}.
Proprio questo motivo ha portato alla creazione degli Scarti Sintetici.
Si fa subito presente che gli Scarti Sintetici sono stati generati a partire da un gruppo di Conformi differente dall'insieme di immagini usate durante l'allenamento.

\begin{figure}[ht] % TODO
  \begin{center}
    \begin{tabular}{c}

      %\begin{subfigure}{\linewidth}
      %  \begin{center}
      %    \includegraphics[width=.3\textwidth]{128___1315_1_0_1_OnLineAnalysis_in}
      %    \includegraphics[width=.3\textwidth]{128___1315_1_0_1_OnLineAnalysis_out}
      %  \end{center}
      %\end{subfigure} \\ \\

      %\begin{subfigure}{\linewidth}
      %  \begin{center}
      %    \includegraphics[width=.3\textwidth]{128___14147_1_0_1_OnLineAnalysis_in}
      %    \includegraphics[width=.3\textwidth]{128___14147_1_0_1_OnLineAnalysis_out}
      %  \end{center}
      %\end{subfigure} \\ \\

      \begin{subfigure}{\linewidth}
        \begin{center}
          \includegraphics[width=.3\textwidth]{128___22886_1_1_1_OnLineAnalysis_in}
          \includegraphics[width=.3\textwidth]{128___22886_1_1_1_OnLineAnalysis_out}
        \end{center}
      \end{subfigure} \\ \\

      \begin{subfigure}{\linewidth}
        \begin{center}
          \includegraphics[width=.3\textwidth]{128___33667_0_0_1_OnLineAnalysis_in}
          \includegraphics[width=.3\textwidth]{128___33667_0_0_1_OnLineAnalysis_out}
        \end{center}
      \end{subfigure}

    \end{tabular}
    \caption{Esempi di Scarti e loro ricostruzione}
    \label{fig:scarti_in_out}
  \end{center}
\end{figure}

L'algoritmo di post-processing è stato sviluppato usando immagini differenza generate da Scarti Sintetici, perché risultano più pulite.
Ma soprattutto perché ci si aspetta che siano anche più verosimili a quelle che si otterrebbero durante la messa in opera del sistema: le carcasse sono state scelte dalla distribuzione dei Conformi. \todo{dire meglio o non dire affatto}

In figura~\ref{fig:post_proc_scarto_sin} si possono vedere l'immagine di partenza (in alto a sinistra), l'immagine ricostruita dall'\textit{autoencoder} (in alto a destra), il risultato del post-processing della differenza fra le due (in basso a destra) e la predizione finale.
L'algoritmo di \textit{post-processing}, ottenuto con metodi empirici, opera in questo modo:
\begin{itemize}
  \item viene calcolato il valore assoluto della differenza \textit{pixel} per \textit{pixel} tra le immagini d'\textit{input} e d'\textit{output}.
    Il risultato di questo passaggio non è stato mostrato perché i valori non sono molto grandi, ciò significa che l'immagine, principalmente nera, contiene alcune aree con \textit{pixel} di colore grigio scuro;

  \item viene effettuata una doppia sogliatura sull'immagine differenza.
    In questo modo tutti i pixel con valori sufficientemente grandi vengono ricolorati di bianco, mentre i restanti sono mappati a $0$;

  %\item viene applicato un filtro che rimuove tutti i \textit{pixel} isolati o che compongono un gruppo troppo piccolo TODO in caso estendere...

  \item viene utilizzato un algoritmo di rilevamento di macchie che sfrutta la differenza di gaussiane.
    Si effettuano varie convoluzioni con filtro di Gauss, in questo modo le macchie più piccole verranno sfumate sempre più fino a scomparire.
    Effettuando differenze tra immagini più o meno sfumate si può determinare se la macchia ha dimensioni sufficientemente grandi e stimarne il centro;
  %https://en.wikipedia.org/wiki/Difference_of_Gaussians

\end{itemize}

Si è verificato che questo tipo di manipolazione non generasse falsi positivi: i valori delle soglie e la dimensione minima delle macchie che si rilevano sono tali da rimuovere il rumore delle immagini differenza.

Va detto che molti Scarti vengono predetti come tali anche a causa delle fasce più scure, che non permettono una ricostruzione fedele  della carcassa oppure risultano grandi a sufficienza nell'immagine differenza.

\begin{figure}[ht] % TODO
  \begin{center}
    \begin{tabular}{cc}

      \includegraphics[width=.3\textwidth]{128___17299_0_1_1_OnLineAnalysis_con_colla_in} &
      \includegraphics[width=.3\textwidth]{128___17299_0_1_1_OnLineAnalysis_con_colla_out} \\
      %\includegraphics[width=.3\textwidth]{128___17299_0_1_1_OnLineAnalysis_con_colla_diff} & 
      \includegraphics[width=.3\textwidth]{128___17299_0_1_1_OnLineAnalysis_con_colla_to_blob} &
      \includegraphics[width=.3\textwidth]{128___17299_0_1_1_OnLineAnalysis_con_colla_detected}

    \end{tabular}
    \caption{Post-processing applicato ad uno Scarto Sintetico}
    \label{fig:post_proc_scarto_sin}
  \end{center}
\end{figure}

\clearpage
\section{I Risultati}
Riassumiamo ora brevemente i risultati ottenuti.
Come si vede nella tabella~\ref{tab:test_predicions}, tutti i Conformi (che non sono stati usati durante l'allenamento) sono stati classificati correttamente.
Viceversa non tutti gli Scarti e gli Scarti Sintetici sono stati classificati come tali.
Per quanto riguarda i secondi va specificato che sono stati scelti a caso trenta Conformi e su ciascuno è stato applicato un ritaglio di colla.
Osservando gli elementi predetti in modo scorretto e la relativa immagine differenza ci si accorge che la colla può passare inosservata se:
\begin{itemize}
  \item ha un colore molto vicino a quello della superficie della carcassa, quindi tende a corrispondere, nell'immagine differenza, ad un area con valori in assoluto piccoli;
  \item si presenta come una striscia sottile.
\end{itemize}

\begin{table}[ht]
  \centering
  \begin{tabular}{||l r r r||}
    \hline
    %\multicolumn{4}{||c||}{tittolo} \\ \hline
    Classe           & Elementi & Predetti come KO & Percentuale \\ \hline \hline
    Conformi         & 314      & 0                & 0\%         \\ \hline
    Scarti           & 30       & 28               & 93.3\%      \\ \hline
    Scarti Sintetici & 30       & 28               & 93.3\%      \\ \hline

  \end{tabular}
  \caption{Predizioni sull'insieme di \textit{Test}}
  \label{tab:test_predicions}
\end{table}

Questi dati sono riportati anche sotto forma di matrice di confusione in tabella~\ref{tab:confusion_matrix}.
Possiamo usare la tabella per ricavare le metriche di \textit{accuracy}, \textit{precision} e \textit{recall} definite come:
\begin{align*} % TODO allineare
  accuracy &= \frac{\text{TP + TN}}{\text{TP + TN + FP + FN}}
            = \frac{56 + 314}{56 + 314 + 4} = 0.989
  \\ \\
  precison &= \frac{\text{TP}}{\text{TP + FP}} 
            = \frac{56}{56} = 1.00
  \\ \\
  recall   &= \frac{\text{TP}}{\text{TP + FN}} 
            = \frac{56}{56 + 4} = 0.933
\end{align*}
Notiamo come la \textit{accuracy}, che indica quante volte viene predetta la classe corretta, sia molto alta.
Non ci sorprende che la \textit{precision} sia così alta perché uno dei nostri obbiettivi era evitare che venissero scartati Conformi.
Quindi si voleva mantenere il numero di Falsi Positivi il più basso possibile.
Il valore più basso è la \textit{recall} ossia che percentuale degli Scarti è stati effettivamente riconosciuta, valore comunque soddisfacente perché corrisponde al 93.3\%.

\begin{table}[ht]
  \centering
  \renewcommand\arraystretch{1.5}
  \setlength\tabcolsep{0pt}
  \begin{tabular}{c >{\bfseries}r @{\hspace{0.7em}}c @{\hspace{0.4em}}c @{\hspace{0.7em}}l}
    \multirow{10}{*}{\parbox{1.1cm}{\bfseries\raggedleft Valore\\ effettivo}} & 
      & \multicolumn{2}{c}{\bfseries Predizione} & \\
    & & \bfseries 60 & \bfseries 314 & \bfseries totale \\
    & p$'$ & \MyBox{56 TP}{} & \MyBox{4 FN}{} & 60 \\[2.4em]
    & n$'$ & \MyBox{0 FP}{} & \MyBox{314 TN}{} & 314 \\
    & totale & 56 & 318 &
  \end{tabular}
  \caption{Matrice di confusione per l'insieme di \textit{Test}}
  \label{tab:confusion_matrix}
\end{table}

Per avere una stima sulle capacità della rete su un numero maggiore di Conformi si è deciso di effettuare delle predizioni anche sulle immagini usate durante l'allenamento.
Generalmente le immagini differenza della carcasse Conformi si presentano quasi interamente nere.
Le poche macchie bianche sono di dimensioni ridotte e distanti tra loro.
Il principale motivo che causa una predizione errata è il fatto che il pezzo sia stato fotografato da una distanza maggiore della media.
Questo significa che le balze non vengono coperte interamente dalla maschera e quindi, dato che l'AE non le può ricostruire, possono risultare come una macchia sufficientemente grande.
Nella tabella~\ref{tab:train_predicions} viene illustrato che il 98.9\% dei Conformi viene identificato correttamente.

\begin{table}[ht]
  \centering
  \begin{tabular}{||l r r r||}
    \hline
    Classe           & Elementi & Predetti come KO & Percentuale \\ \hline \hline
    Conformi         & 1375     & 15               & 1.1\%       \\ \hline

  \end{tabular}
  \caption{Predizioni sull'insieme di \textit{Train}}
  \label{tab:train_predicions}
\end{table}

